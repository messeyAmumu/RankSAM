<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>RankSAM: Lightweight Adapters and Prompt Generation in Zero-Shot Semantic Segmentation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">RankSAM: Lightweight Adapters and Prompt Generation in Zero-Shot Semantic Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              Yue Zhuo, Zhaocheng Xu, Di Zhou, Pengpeng Xu, Yan Tian
              <!-- <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=BB2GTFoAAAAJ" target="_blank">Yan Tian</a>,</span>
                <span class="author-block">
                  <a href="https://github.com/longxinglx" target="_blank">Long Xing</a>,</span>
                  <span class="author-block">
                    <a href="https://sites.google.com/view/weipingding" target="_blank">Weiping Ding</a>
                  </span> -->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Zhejiang University</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <!-- TODO: 论文链接待修改 -->
                        <!-- <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark"> -->
                        <a href="" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  </span>

                  <!-- Github link -->
                  <!-- TODO: 代码链接待修改 -->
                  <span class="link-block">
                    <!-- <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark"> -->
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a> -->
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 流程图 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="item has-text-centered">
      <!-- Your image here -->
      <img src="static/images/framework.png" alt="MY ALT TEXT">
      <h2 class="subtitle has-text-centered">
        Figure 2: An illustration of the RankSAM.
      </h2>
      <div class="content has-text-justified">
        <p>
          Given an RGB image, the coarse-to-fine rank modulation in SAM encoder distincts the lower and higher-rank subspaces and activates the corresponding components by using a hierarchical gating mechanism.
          After that, automatic prompt generation is proposed to efficiently generate essential prompts for precise mask output, where the prompt candidate
          generation identifies essential prompt locations and redundant prompt deletion enhances efficiency in prompt generation.
        </p>
      </div>
    </div>
  </div>
</div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Zero-shot segmentation based plays a crucial role in neurocomputing such as embodied intelligence systems and autonomous driving technologies. 
            However, current approaches struggle to preserve the intrinsic ability of SAM to generalize as input quality declines. 
            In addition, prompt generation still faces an embarrassment in the balance between effectiveness and efficiency. 
            Motivated by low-rank adaptation (LoRA) , we design RankSAM which integrates slim, adaptable modules into the middle layers of the frozen SAM framework. 
            These modules dynamically fine-tune the operational rank of their weight matrices in response to input data, leveraging a trainable gating mechanism to selectively activate specific (rank-1) matrix components as needed.
            In addition, a learnable prompt predictor is designed to learn and generate prompt confidence maps and point prompts, and any remaining prompts that would produce the same mask are filtered out to enhance efficiency in prompt generation.
            The experimental results in multiple datasets indicate that our approach improves the mean intersection over union (mIoU) by a margin of 2.5-2.8% compared to the prevailing approaches.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Methods -->
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Methods</h2>
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item has-text-centered">
        <img src="static/images/CRM.png" alt="MY ALT TEXT" style="display: inline-block;" />
        <h2 class="subtitle has-text-centered">
        Figure 3: An illustration of the coarse-to-fine rank modulation.
        </h2>
    </div>
    <div class="item has-text-centered">
      <img src="static/images/APG.png" alt="MY ALT TEXT" style="display: inline-block;" />
      <h2 class="subtitle has-text-centered">
        Figure 4: An illustration of the automatic prompt generation.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Example Image -->
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Example</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/ab_effect.png" alt="MY ALT TEXT"/>
          <h2 class="subtitle has-text-centered">
            Figure 5: Evaluation of the proposed modules on the Hangzhou traffic dataset.
          </h2>
        </div>
       <div class="item">
        <img src="static/images/good.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Figure 7: Qualitative comparisons between MobileSAMv2, RobustSAM, and our approach on the Hangzhou traffic dataset are illustrated.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/bad.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Figure 9: Illustration of the drawbacks in our approach.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Quantitative Comparison -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Quantitative Comparison</h2>
      <div class="item has-text-centered">
        <img src="static/images/effect.png" alt="MY ALT TEXT" style="display: inline-block;" />
        <h2 class="subtitle has-text-centered">
          Table 2: Effectiveness comparison of the Hangzhou traffic, GM traffic, and MSCOCO datasets.
        </h2>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->

      <!-- Paper video. -->
      
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->

            <!-- Youtube embed code here -->
            
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->

            <!-- Your video file here -->

            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->

            <!-- Your video file here -->
            
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            
            <!-- Your video file here -->

            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<!-- TODO: 待修改 -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
